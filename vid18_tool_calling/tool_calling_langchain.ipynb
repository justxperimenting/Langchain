{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "114d0382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from ipywidgets) (9.4.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: colorama in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in d:\\2025_coding\\campusx\\langchain\\venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Downloading widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 1.8/2.2 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 8.9 MB/s  0:00:00\n",
      "Installing collected packages: widgetsnbextension, jupyterlab_widgets, ipywidgets\n",
      "\n",
      "   ---------------------------------------- 0/3 [widgetsnbextension]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   -------------------------- ------------- 2/3 [ipywidgets]\n",
      "   ---------------------------------------- 3/3 [ipywidgets]\n",
      "\n",
      "Successfully installed ipywidgets-8.1.7 jupyterlab_widgets-3.0.15 widgetsnbextension-4.0.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Connection timed out while downloading.\n",
      "WARNING: Attempting to resume incomplete download (0 bytes/139 kB, attempt 1)\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/58/6a/9166369a2f092bd286d24e6307de555d63616e8ddb373ebad2b5635ca4cd/ipywidgets-8.1.7-py3-none-any.whl\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001F364B71D00>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/58/6a/9166369a2f092bd286d24e6307de555d63616e8ddb373ebad2b5635ca4cd/ipywidgets-8.1.7-py3-none-any.whl\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001F364B71FA0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/58/6a/9166369a2f092bd286d24e6307de555d63616e8ddb373ebad2b5635ca4cd/ipywidgets-8.1.7-py3-none-any.whl\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000001F364B5FE00>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/58/6a/9166369a2f092bd286d24e6307de555d63616e8ddb373ebad2b5635ca4cd/ipywidgets-8.1.7-py3-none-any.whl\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install -q langchain-core requests\n",
    "!{sys.executable} -m pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8116b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7861d818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d675b8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool create\n",
    "\n",
    "@tool\n",
    "def multiply(a : int , b : int) -> int:\n",
    "    \"\"\"Given two numbers a and b return their product\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f4ed76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(multiply.invoke({'a':3,'b':5}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca4586a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multiply'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8a055bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given two numbers a and b return their product\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a': {'title': 'A', 'type': 'integer'},\n",
       " 'b': {'title': 'B', 'type': 'integer'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(multiply.description)\n",
    "multiply.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29c11c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool binding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "065d3ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= 'mistralai/Mixtral-8x7B-Instruct-v0.1',\n",
    "    task= 'text-generation'\n",
    ")\n",
    "\n",
    "# mistral can't do tool calling\n",
    "\n",
    "llm_model = ChatHuggingFace(llm = llm)\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34d870b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_with_tools = llm_model.bind_tools([multiply])\n",
    "# now the llm model has a tool which can multiply two numbers\n",
    "\n",
    "# Note:- not every llm model can bind tools with itself "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a737b0f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\" Hello! I'm just a computer program, so I don't have the ability to feel emotions or have a physical state like a human does. I'm here to help answer any questions you might have. Is there something specific you would like to ask?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 11, 'total_tokens': 66}, 'model_name': 'mistralai/Mistral-7B-Instruct-v0.2', 'system_fingerprint': '', 'finish_reason': 'stop', 'logprobs': None}, id='run--28c7bf59-a49d-44be-80ce-f86b1e735080-0', usage_metadata={'input_tokens': 11, 'output_tokens': 55, 'total_tokens': 66})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model_with_tools.invoke('Hi, How are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5a71cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm_model_with_tools.invoke('you must apply the multiply function and then respond whether you can multiply 3 with 10')\n",
    "\n",
    "# mistral can't do tool calling therefore it automatically gives ai response instead of json schema\n",
    "# in video, nitish used openai chat , therefore he got schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1606f690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=' Yes, I can confirm that I can apply the multiply function to the numbers 3 and 10. The product of 3 and 10 is 30.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 187, 'total_tokens': 225}, 'model_name': 'mistralai/Mixtral-8x7B-Instruct-v0.1', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run--e8280e0d-a95b-4465-8606-ef6c62b3009d-0' usage_metadata={'input_tokens': 187, 'output_tokens': 38, 'total_tokens': 225}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318eeb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f7779",
   "metadata": {},
   "source": [
    "### *Can't execute codes from here as the Hugging face model 'Mistral' does support tool calling , and campusx used openai chat for tool calling*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facf512c",
   "metadata": {},
   "source": [
    "desired result = llm_model_with_tools.invoke('can you multiply 3 with 10')\n",
    "was\n",
    "\n",
    "result.tool_calls[0] 's output:\n",
    "\n",
    "{'name': 'multiply',\n",
    "    'args':{'a':3,'b':10},\n",
    "    'id' : some string,\n",
    "    'type':'tool call'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62999963",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply.invoke(result.tool_calls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6034f99",
   "metadata": {},
   "source": [
    "## Making a currency convertor agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f02ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import InjectedToolArg\n",
    "from typing import Annotated\n",
    "\n",
    "@tool\n",
    "def get_conversion_factor(base_currency : str,converted_currency : str) -> float:\n",
    "    \"\"\"This function will get the conversion factor from base currency to the desired conversion currency, this will give real time curreny conversion\"\"\"\n",
    "    \n",
    "    url = f\"someUrlForApiKey/{base_currency}/{converted_currency}\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "@tool\n",
    "def convert(base_currency_value:int,conversion_factor:Annotated[float,InjectedToolArg]) -> float:\n",
    "    \"\"\"Given a currency conversion rate , this function calculates the target currency value from a given base currency value\"\"\"\n",
    "    \n",
    "    # Annotated will tell the LLM to not try to fill this argument, the developer will inject this value after running earlier tools\n",
    "    \n",
    "    return base_currency_value*conversion_factor    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83e9b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool binding\n",
    "llm1 = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c3e6fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm1.bind_tools([get_conversion_factor,convert])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fbffd2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage('What is the conversion factor between USD and INR, and based on that can you convert 10 usd into inr')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't run this cell as i don't have openai api token\n",
    "ai_message = llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5144139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c0b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69282c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "for tool_call in ai_message.tool_calls :\n",
    "    # execute the 1st tool and get the value in conversion rate\n",
    "    if tool_call['name'] == 'get_conversion_factor':\n",
    "        tool_message1 = get_conversion_factor.invoke(tool_call)\n",
    "    \n",
    "    # fetch this conversion rate\n",
    "    conversion_rate = json.loads(tool_message1.content)['conversion_rate']\n",
    "        # this json will load the content of tool_message1 as dictionary\n",
    "        \n",
    "    #append this tool message to messages list\n",
    "    messages.appen(tool_message1)\n",
    "    # execute the 2nd tool the conversion rate from tool open\n",
    "    if(tool_call['name'] == 'convert'):\n",
    "        # fetch the currrent argument\n",
    "        tool_call['arg']['conversion_factor'] = conversion_rate\n",
    "        tool_message2 = convert.invoke(tool_call)\n",
    "        messages.appen(tool_message2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools.invoke(messages).content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
